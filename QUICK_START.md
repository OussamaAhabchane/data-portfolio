# ğŸš€ Guide de DÃ©marrage Rapide - Portfolio Data Science

## ğŸ“¦ Contenu du Portfolio

**4 projets complets** prÃªts Ã  Ãªtre utilisÃ©s :

### 1ï¸âƒ£ Stock Sentiment Prediction (Finance + NLP)
- **ThÃ©matique** : Analyse de sentiment financier et prÃ©diction de prix
- **Dataset** : Yahoo Finance + Sentiment synthÃ©tique
- **CompÃ©tences** : Time series, NLP, Feature engineering
- **Fichiers clÃ©s** : 
  - `data/download_data.py` - TÃ©lÃ©charge les donnÃ©es boursiÃ¨res
  - `src/sentiment_analyzer.py` - Analyse de sentiment
  - `src/feature_engineering.py` - Features techniques avancÃ©es

### 2ï¸âƒ£ Fraud Detection (Finance + ML)
- **ThÃ©matique** : DÃ©tection de fraudes bancaires
- **Dataset** : Kaggle Credit Card Fraud
- **CompÃ©tences** : DonnÃ©es dÃ©sÃ©quilibrÃ©es, SMOTE, XGBoost
- **Fichiers clÃ©s** :
  - `src/train_model.py` - Pipeline complet de ML
  - Comparaison de multiples approches de sampling

### 3ï¸âƒ£ E-commerce Review Analysis (NLP)
- **ThÃ©matique** : Analyse de sentiment et Topic Modeling
- **Dataset** : Kaggle Women's E-commerce Reviews
- **CompÃ©tences** : NLP avancÃ©, LDA, Recommendation
- **Fichiers clÃ©s** :
  - `src/preprocessing.py` - Preprocessing NLP complet
  - Topic modeling et systÃ¨me de recommandation

### 4ï¸âƒ£ Customer Churn Prediction (Finance + Marketing)
- **ThÃ©matique** : PrÃ©diction d'attrition client et CLV
- **Dataset** : Kaggle Telco Churn
- **CompÃ©tences** : Classification, RFM, Feature engineering
- **Fichiers clÃ©s** :
  - `src/rfm.py` - Segmentation RFM complÃ¨te
  - Analyse de valeur client

---

## ğŸ¯ Comment Utiliser ce Portfolio

### Option 1 : Upload sur GitHub (RecommandÃ©)

```bash
# 1. CrÃ©er un nouveau repo sur GitHub
# 2. Dans votre terminal local :
cd data-portfolio
git init
git add .
git commit -m "Initial commit - Data Science Portfolio"
git branch -M main
git remote add origin https://github.com/VOTRE-USERNAME/data-portfolio.git
git push -u origin main
```

### Option 2 : Travailler localement

```bash
# 1. Extraire le dossier data-portfolio
# 2. Ouvrir un terminal dans le dossier
cd data-portfolio

# 3. ExÃ©cuter le setup automatique
python setup.py

# 4. Activer l'environnement virtuel
# Sur Mac/Linux :
source venv/bin/activate
# Sur Windows :
venv\Scripts\activate

# 5. Choisir un projet
cd 01-stock-sentiment-prediction

# 6. TÃ©lÃ©charger les donnÃ©es
python data/download_data.py

# 7. Lancer Jupyter
jupyter notebook notebooks/
```

---

## ğŸ“‹ Installation Manuelle (si setup.py ne fonctionne pas)

### Ã‰tape 1 : CrÃ©er l'environnement virtuel
```bash
python -m venv venv
source venv/bin/activate  # Mac/Linux
# OU
venv\Scripts\activate  # Windows
```

### Ã‰tape 2 : Installer les dÃ©pendances
```bash
# Installation globale
pip install -r requirements.txt

# OU installation par projet
cd 01-stock-sentiment-prediction
pip install -r requirements.txt
```

### Ã‰tape 3 : TÃ©lÃ©charger ressources NLP (pour projet 3)
```bash
python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords'); nltk.download('wordnet')"
python -m spacy download en_core_web_sm
```

---

## ğŸ“Š TÃ©lÃ©chargement des Datasets

### Projet 1 - Stock Sentiment
âœ… **Automatique** : Le script tÃ©lÃ©charge via yfinance
```bash
python data/download_data.py
```

### Projet 2 - Fraud Detection
ğŸ“¥ **Manuel** : TÃ©lÃ©charger depuis Kaggle
1. Aller sur : https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud
2. TÃ©lÃ©charger `creditcard.csv`
3. Placer dans `02-fraud-detection/data/raw/`

### Projet 3 - E-commerce Reviews
ğŸ“¥ **Manuel** : TÃ©lÃ©charger depuis Kaggle
1. Aller sur : https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews
2. TÃ©lÃ©charger le CSV
3. Placer dans `03-ecommerce-review-analysis/data/raw/`

### Projet 4 - Customer Churn
ğŸ“¥ **Manuel** : TÃ©lÃ©charger depuis Kaggle
1. Aller sur : https://www.kaggle.com/datasets/blastchar/telco-customer-churn
2. TÃ©lÃ©charger `WA_Fn-UseC_-Telco-Customer-Churn.csv`
3. Placer dans `04-customer-churn-prediction/data/raw/`

---

## ğŸ¨ Personnalisation pour Votre Profil

### 1. Mettre Ã  jour le README principal
Ã‰ditez `README.md` et remplacez :
- `[votre-username]` â†’ Votre nom d'utilisateur GitHub
- `[votre-profil]` â†’ Lien vers votre LinkedIn
- `votre.email@example.com` â†’ Votre email

### 2. Ajouter vos rÃ©sultats
AprÃ¨s avoir exÃ©cutÃ© les projets :
- Remplacez les rÃ©sultats "attendus" par vos rÃ©sultats rÃ©els
- Ajoutez vos propres visualisations
- Documentez vos insights

### 3. Personnaliser les analyses
- Testez diffÃ©rents hyperparamÃ¨tres
- Ajoutez vos propres features
- CrÃ©ez des visualisations supplÃ©mentaires

---

## ğŸ’¡ Conseils pour les Recruteurs

### Structurez votre prÃ©sentation :

1. **README accrocheur** âœ… (dÃ©jÃ  fait)
2. **Notebooks bien commentÃ©s** ğŸ“ (Ã  faire dans Jupyter)
3. **Code propre et modulaire** âœ… (dÃ©jÃ  structurÃ©)
4. **Visualisations professionnelles** ğŸ“Š (Ã  gÃ©nÃ©rer)
5. **Documentation complÃ¨te** ğŸ“š (dÃ©jÃ  fournie)

### Mettez en avant :
- âœ¨ **CompÃ©tences techniques** : ListÃ©es dans chaque README
- ğŸ“ˆ **RÃ©sultats quantifiables** : MÃ©triques et performances
- ğŸ’¼ **Business impact** : Insights actionnables
- ğŸ”§ **Best practices** : Code modulaire, tests, documentation

---

## ğŸ› Troubleshooting

### Erreur : "Module not found"
```bash
pip install [nom-du-module]
# OU rÃ©installer tous les requirements
pip install -r requirements.txt
```

### Erreur : "NLTK resources not found"
```bash
python -c "import nltk; nltk.download('all')"
```

### Erreur : "spaCy model not found"
```bash
python -m spacy download en_core_web_sm
```

### ProblÃ¨me de mÃ©moire (dataset trop gros)
```python
# Lire seulement une partie du dataset
df = pd.read_csv('data.csv', nrows=10000)
```

### Jupyter ne dÃ©marre pas
```bash
pip install --upgrade jupyter notebook
jupyter notebook
```

---

## ğŸ“š Ressources SupplÃ©mentaires

### Apprentissage
- **Kaggle Learn** : https://www.kaggle.com/learn
- **Fast.ai** : https://www.fast.ai/
- **Coursera ML** : https://www.coursera.org/learn/machine-learning

### Datasets
- **Kaggle** : https://www.kaggle.com/datasets
- **UCI ML Repository** : https://archive.ics.uci.edu/ml/
- **Data.gov** : https://www.data.gov/

### Documentation
- **Scikit-learn** : https://scikit-learn.org/
- **Pandas** : https://pandas.pydata.org/
- **Matplotlib** : https://matplotlib.org/

---

## âœ… Checklist avant de publier sur GitHub

- [ ] Remplacer les placeholders dans README.md
- [ ] GÃ©nÃ©rer et ajouter des visualisations
- [ ] Tester que les notebooks s'exÃ©cutent
- [ ] VÃ©rifier que .gitignore fonctionne (pas de gros fichiers)
- [ ] Ajouter une LICENSE (MIT recommandÃ©e)
- [ ] CrÃ©er des badges pour le README (optional)
- [ ] Ajouter des screenshots des visualisations
- [ ] Documenter vos rÃ©sultats finaux

---

## ğŸ¯ Prochaines Ã‰tapes

### Semaine 1-2 : Setup et exploration
- âœ… Installation complÃ¨te
- âœ… TÃ©lÃ©chargement des datasets
- ğŸ“Š ExÃ©cution des notebooks d'exploration

### Semaine 3-4 : ModÃ©lisation
- ğŸ¤– EntraÃ®nement des modÃ¨les
- ğŸ“ˆ Optimisation des hyperparamÃ¨tres
- ğŸ“Š GÃ©nÃ©ration des visualisations

### Semaine 5-6 : Documentation
- ğŸ“ Documenter vos rÃ©sultats
- ğŸ¨ CrÃ©er des visualisations professionnelles
- ğŸ“š RÃ©diger vos insights

### Semaine 7-8 : Publication
- ğŸ™ Push sur GitHub
- ğŸ’¼ Ajouter Ã  votre CV/LinkedIn
- ğŸ¤ PrÃ©parer votre pitch

---

## ğŸ†˜ Besoin d'Aide ?

- **Documentation projet** : Voir README.md de chaque projet
- **Issues techniques** : VÃ©rifier requirements et versions Python
- **Questions dataset** : Consulter la page Kaggle du dataset
- **AmÃ©lioration code** : Les scripts sont commentÃ©s et modulaires

---

## ğŸŒŸ Bonus : AmÃ©liorations Possibles

### Niveau DÃ©butant
- Ajouter plus de visualisations
- Tester d'autres hyperparamÃ¨tres
- CrÃ©er un rapport PDF automatique

### Niveau IntermÃ©diaire
- CrÃ©er une API Flask/FastAPI
- Ajouter un dashboard Streamlit
- ImplÃ©menter du feature engineering avancÃ©

### Niveau AvancÃ©
- Deep Learning (LSTM, Transformers)
- MLOps (MLflow, DVC)
- DÃ©ploiement cloud (AWS, GCP, Azure)
- CI/CD avec GitHub Actions

---

**Bon courage avec votre portfolio ! ğŸš€**

Si vous avez des questions, consultez d'abord les README des projets - tout est documentÃ© en dÃ©tail.
