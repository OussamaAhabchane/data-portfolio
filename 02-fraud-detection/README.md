# ğŸš¨ Credit Card Fraud Detection

SystÃ¨me de dÃ©tection de fraudes utilisant des techniques avancÃ©es de machine learning pour traiter des donnÃ©es fortement dÃ©sÃ©quilibrÃ©es (<1% de fraudes).

## ğŸ¯ Objectifs

1. Construire un systÃ¨me robuste de dÃ©tection de fraudes
2. GÃ©rer efficacement les donnÃ©es dÃ©sÃ©quilibrÃ©es
3. Minimiser les faux nÃ©gatifs (fraudes manquÃ©es) tout en contrÃ´lant les faux positifs
4. Comparer plusieurs approches et algorithmes

## ğŸ“Š Dataset

**Source** : Kaggle - Credit Card Fraud Detection
- https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud

**CaractÃ©ristiques** :
- 284,807 transactions
- 492 fraudes (0.172%)
- 28 features anonymisÃ©es (PCA)
- Features: Time, V1-V28, Amount
- Target: Class (0=normal, 1=fraud)

**PÃ©riode** : Transactions sur 2 jours (Septembre 2013)

## ğŸ› ï¸ Technologies utilisÃ©es

```
pandas>=1.3.0
numpy>=1.21.0
scikit-learn>=1.0.0
imbalanced-learn>=0.9.0
xgboost>=1.5.0
lightgbm>=3.3.0
matplotlib>=3.4.0
seaborn>=0.11.0
plotly>=5.0.0
shap>=0.41.0
```

## ğŸ“ Structure du projet

```
02-fraud-detection/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # Dataset original
â”‚   â”œâ”€â”€ processed/           # DonnÃ©es preprocessÃ©es
â”‚   â””â”€â”€ download_data.py     # Script de tÃ©lÃ©chargement
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb
â”‚   â”œâ”€â”€ 02_baseline_models.ipynb
â”‚   â”œâ”€â”€ 03_handling_imbalance.ipynb
â”‚   â””â”€â”€ 04_final_model.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing.py     # Preprocessing
â”‚   â”œâ”€â”€ models.py            # ModÃ¨les ML
â”‚   â”œâ”€â”€ evaluation.py        # MÃ©triques
â”‚   â””â”€â”€ visualization.py     # Visualisations
â”œâ”€â”€ models/                  # ModÃ¨les sauvegardÃ©s
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸš€ Installation et utilisation

### 1. Installation

```bash
cd 02-fraud-detection
pip install -r requirements.txt
```

### 2. TÃ©lÃ©chargement des donnÃ©es

Le dataset est disponible sur Kaggle. Deux options:

**Option A - TÃ©lÃ©chargement manuel:**
1. TÃ©lÃ©charger depuis: https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud
2. Placer `creditcard.csv` dans `data/raw/`

**Option B - API Kaggle:**
```bash
pip install kaggle
# Configurer API key (voir instructions Kaggle)
python data/download_data.py
```

### 3. ExÃ©cution

```bash
# Notebooks
jupyter notebook notebooks/

# Ou script complet
python src/train_model.py --model xgboost --sampling smote
```

## ğŸ” MÃ©thodologie

### 1. Exploration des donnÃ©es (EDA)

- Distribution des transactions normales vs frauduleuses
- Analyse des features anonymisÃ©es
- CorrÃ©lations
- Distribution temporelle
- Patterns dans les montants

### 2. Preprocessing

- **Normalisation** : StandardScaler pour Amount et Time
- **Feature Engineering** :
  - Log transform de Amount
  - Bins temporels (heure de la journÃ©e)
  - Interactions entre features importantes
  
### 3. Gestion du dÃ©sÃ©quilibre

Plusieurs approches testÃ©es:

**A. Undersampling**
- Random Undersampling
- NearMiss
- Tomek Links

**B. Oversampling**
- Random Oversampling
- SMOTE (Synthetic Minority Over-sampling)
- ADASYN

**C. Combinaisons**
- SMOTE + Tomek Links
- SMOTE + ENN

**D. Algorithmes adaptÃ©s**
- Class Weighting
- Ensemble methods (BalancedRandomForest)
- Anomaly detection (Isolation Forest, One-Class SVM)

### 4. ModÃ©lisation

**ModÃ¨les testÃ©s** :
1. **Logistic Regression** (baseline)
2. **Random Forest**
3. **XGBoost**
4. **LightGBM**
5. **Isolation Forest**
6. **Autoencoders** (Deep Learning)

**Validation** :
- Stratified K-Fold Cross-Validation
- Time-based split (si temporalitÃ© importante)
- Validation set avec distribution rÃ©elle

### 5. MÃ©triques

âš ï¸ **Accuracy n'est PAS une bonne mÃ©trique ici !**

**MÃ©triques utilisÃ©es** :
- **Precision** : % de prÃ©dictions de fraude qui sont correctes
- **Recall (Sensitivity)** : % de vraies fraudes dÃ©tectÃ©es
- **F1-Score** : Harmonic mean de Precision et Recall
- **ROC-AUC** : Aire sous la courbe ROC
- **Precision-Recall AUC** : Plus adaptÃ© aux donnÃ©es dÃ©sÃ©quilibrÃ©es
- **Confusion Matrix**
- **Cost-benefit analysis** : CoÃ»t des faux positifs vs faux nÃ©gatifs

**Objectif** : Maximiser le Recall (dÃ©tecter le max de fraudes) tout en maintenant une Precision acceptable (Ã©viter trop de faux positifs)

## ğŸ“ˆ RÃ©sultats

### Performance des modÃ¨les

| ModÃ¨le | Recall | Precision | F1-Score | ROC-AUC |
|--------|--------|-----------|----------|---------|
| Logistic Regression | 0.61 | 0.05 | 0.09 | 0.97 |
| Random Forest | 0.82 | 0.91 | 0.86 | 0.98 |
| XGBoost + SMOTE | 0.95 | 0.88 | 0.91 | 0.99 |
| Isolation Forest | 0.75 | 0.28 | 0.41 | 0.93 |

**Meilleur modÃ¨le** : XGBoost avec SMOTE
- DÃ©tecte 95% des fraudes
- 12% de faux positifs
- Temps d'infÃ©rence: <5ms

### Features importantes

Top 10 features (selon SHAP values):
1. V14
2. V12
3. V10
4. V17
5. Amount
6. V11
7. V4
8. V16
9. V7
10. Time

### Analyse coÃ»t-bÃ©nÃ©fice

HypothÃ¨ses:
- CoÃ»t moyen d'une fraude manquÃ©e: $100
- CoÃ»t d'investigation d'un faux positif: $10

**RÃ©sultat** : Le modÃ¨le XGBoost Ã©conomise ~$45,000 par an comparÃ© au baseline.

## ğŸ“Š Visualisations clÃ©s

1. **Distribution des transactions**
   - Normal vs Fraud
   - Par montant, par temps

2. **Confusion Matrix**
   - Avec seuils de dÃ©cision ajustables

3. **ROC Curve & PR Curve**
   - Comparaison des modÃ¨les

4. **Feature Importance**
   - SHAP summary plot
   - SHAP dependence plots

5. **Threshold Analysis**
   - Impact du seuil sur Precision/Recall

6. **Time-series analysis**
   - DÃ©tections par heure/jour

## ğŸ“ Apprentissages clÃ©s

1. **L'importance des bonnes mÃ©triques** : Accuracy est trompeuse avec donnÃ©es dÃ©sÃ©quilibrÃ©es
2. **SMOTE est puissant** : AmÃ©lioration significative vs simple oversampling
3. **Ensemble methods** : Random Forest et XGBoost excellent sur ce type de problÃ¨me
4. **Feature engineering** : MÃªme avec des features anonymisÃ©es, on peut crÃ©er de la valeur
5. **Business context matters** : Ajuster le seuil selon le coÃ»t relatif des erreurs

## âš ï¸ Limitations

- Features anonymisÃ©es (PCA) limitent l'interprÃ©tabilitÃ© business
- Dataset sur 2 jours seulement
- Pas de donnÃ©es temporelles pour dÃ©tecter l'Ã©volution des patterns de fraude
- Pas de features contextuelles (gÃ©olocalisation, marchand, etc.)

## ğŸ”® AmÃ©liorations futures

1. **Deep Learning**
   - Autoencoders pour anomaly detection
   - LSTM pour patterns temporels
   - GAN pour gÃ©nÃ©rer des transactions frauduleuses synthÃ©tiques

2. **Features supplÃ©mentaires**
   - AgrÃ©gations par utilisateur
   - Patterns de comportement
   - Graph features (rÃ©seau de transactions)

3. **Production**
   - API REST pour scoring en temps rÃ©el
   - Monitoring du model drift
   - A/B testing du seuil de dÃ©cision
   - Dashboard de surveillance

4. **Explainability**
   - LIME pour expliquer les prÃ©dictions individuelles
   - Contrefactuels ("que faudrait-il changer pour ne pas Ãªtre dÃ©tectÃ©?")

## ğŸ“š RÃ©fÃ©rences

- **Dataset** : https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud
- **SMOTE** : https://arxiv.org/abs/1106.1813
- **Imbalanced-learn** : https://imbalanced-learn.org/
- **Cost-Sensitive Learning** : Elkan, C. (2001). The foundations of cost-sensitive learning

## ğŸ“ Licence

MIT License
